{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f46f29ac-11d0-44f2-8ee3-1e2897012467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 265,512 English-Spanish sentence pairs.\n"
     ]
    }
   ],
   "source": [
    "valid_rows = []\n",
    "\n",
    "file_path = \"Sentence pairs in English-Spanish.tsv\"\n",
    "\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split('\\t')\n",
    "        if len(parts) == 4:\n",
    "            en = parts[1].strip()\n",
    "            es = parts[3].strip()\n",
    "            if en and es:\n",
    "                valid_rows.append([en, es])\n",
    "\n",
    "print(f\"Loaded {len(valid_rows):,} English-Spanish sentence pairs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ed15298-0135-4f11-9596-53f77cb4e91e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>es</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Let's try something.</td>\n",
       "      <td>¡Intentemos algo!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have to go to sleep.</td>\n",
       "      <td>Tengo que irme a dormir.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Today is June 18th and it is Muiriel's birthday!</td>\n",
       "      <td>¡Hoy es 18 de junio y es el cumpleaños de Muir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Today is June 18th and it is Muiriel's birthday!</td>\n",
       "      <td>¡Hoy es el 18 de junio y es el cumpleaños de M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Muiriel is 20 now.</td>\n",
       "      <td>Ahora, Muiriel tiene 20 años.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 en  \\\n",
       "0                              Let's try something.   \n",
       "1                            I have to go to sleep.   \n",
       "2  Today is June 18th and it is Muiriel's birthday!   \n",
       "3  Today is June 18th and it is Muiriel's birthday!   \n",
       "4                                Muiriel is 20 now.   \n",
       "\n",
       "                                                  es  \n",
       "0                                  ¡Intentemos algo!  \n",
       "1                           Tengo que irme a dormir.  \n",
       "2  ¡Hoy es 18 de junio y es el cumpleaños de Muir...  \n",
       "3  ¡Hoy es el 18 de junio y es el cumpleaños de M...  \n",
       "4                      Ahora, Muiriel tiene 20 años.  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(valid_rows, columns=[\"en\", \"es\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08ce6aab-26e5-4c56-be94-feca8eb53ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process data into token IDs for transformer\n",
    "from collections import Counter\n",
    "import torch\n",
    "\n",
    "def build_vocab(sentences, max_vocab=5000):\n",
    "    counter = Counter()\n",
    "    for sent in sentences:\n",
    "        tokens = sent.lower().split()\n",
    "        counter.update(tokens)\n",
    "    vocab = {\"<pad>\":0, \"<unk>\":1, \"<bos>\":2, \"<eos>\":3}\n",
    "    most_common = counter.most_common(max_vocab - len(vocab))\n",
    "    for i, (word, _) in enumerate(most_common, len(vocab)):\n",
    "        vocab[word] = i\n",
    "    return vocab\n",
    "\n",
    "def encode_sentence(sentence, vocab):\n",
    "    tokens = sentence.lower().split()\n",
    "    ids = [vocab.get(t, vocab[\"<unk>\"]) for t in tokens]\n",
    "    return [vocab[\"<bos>\"]] + ids + [vocab[\"<eos>\"]]\n",
    "\n",
    "en_vocab = build_vocab(df[\"en\"])\n",
    "es_vocab = build_vocab(df[\"es\"])\n",
    "\n",
    "encoded_pairs = [(encode_sentence(en, en_vocab), encode_sentence(es, es_vocab)) for en, es in zip(df[\"en\"], df[\"es\"])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23de4291-d4a8-41a6-803b-00c1ebe4dcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Small Transformer to stay within 100 neural unit limit\n",
    "import torch.nn as nn\n",
    "\n",
    "class SmallTransformer(nn.Module):\n",
    "    def __init__(self, src_vocab_size, tgt_vocab_size, emb_size=32, nhead=2, dim_feedforward=64, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.src_emb = nn.Embedding(src_vocab_size, emb_size)\n",
    "        self.tgt_emb = nn.Embedding(tgt_vocab_size, emb_size)\n",
    "        self.transformer = nn.Transformer(d_model=emb_size, nhead=nhead, \n",
    "                                          num_encoder_layers=num_layers, \n",
    "                                          num_decoder_layers=num_layers, \n",
    "                                          dim_feedforward=dim_feedforward)\n",
    "        self.fc = nn.Linear(emb_size, tgt_vocab_size)\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        src_mask = self.transformer.generate_square_subsequent_mask(src.size(1)).to(src.device)\n",
    "        tgt_mask = self.transformer.generate_square_subsequent_mask(tgt.size(1)).to(tgt.device)\n",
    "\n",
    "        src_emb = self.src_emb(src).permute(1, 0, 2)\n",
    "        tgt_emb = self.tgt_emb(tgt).permute(1, 0, 2)\n",
    "\n",
    "        output = self.transformer(src_emb, tgt_emb, src_mask=src_mask, tgt_mask=tgt_mask)\n",
    "        return self.fc(output.permute(1, 0, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c48878-9ce0-4fe4-a822-dae2025d8fbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
